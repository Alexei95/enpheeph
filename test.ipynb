{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitcustomfaultinjectionframeworkpytorch15conda1f9e4070c157481e9e620503dd67ffba",
   "display_name": "Python 3.8.3 64-bit ('CustomFaultInjectionFrameworkPyTorch1_5': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import src.dnn.datasets\n",
    "import src.dnn.models\n",
    "import src.dnn.test\n",
    "import src.dnn.train\n",
    "import src.dnn.utils\n",
    "\n",
    "train_dataset, test_dataset = src.dnn.datasets.DATASETS['MNIST'](train_batch_size=128, test_batch_size=128, path='datasets')\n",
    "#model = src.dnn.train.train(src.dnn.models.MODELS['LeNet5'](), cuda=True, train_dataset=train_dataset, optimizer_class=torch.optim.Adam, optimizer_args={}, loss=torch.nn.CrossEntropyLoss(), n_epochs=1)\n",
    "model = src.dnn.utils.init_model(src.dnn.models.MODELS['LeNet5'], model_args={}, use_saved_model=True, model_save_path='models/lenet5.pkl', cuda=True, train_dataset=train_dataset, optimizer_class=torch.optim.Adam, optimizer_args={}, loss=torch.nn.CrossEntropyLoss(), n_epochs=1)\n",
    "loaded_model = src.dnn.utils.load_model(src.dnn.models.MODELS['LeNet5'](), 'models/lenet5.pkl')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parameter containing:\ntensor([ 0.0557,  0.0186, -0.0026, -0.1097,  0.0753, -0.0255,  0.0785,  0.0463,\n         0.0458,  0.0891], device='cuda:0', requires_grad=True)\nParameter containing:\ntensor([ 0.0557,  0.0186, -0.0026, -0.1097,  0.0753, -0.0255,  0.0785,  0.0463,\n         0.0458,  0.0891], device='cuda:0', requires_grad=True)\n{'accuracy': 0.9712, 'loss': 0.0007349000092595815}\n{'accuracy': 0.9712, 'loss': 0.0007349000092595815}\n"
    }
   ],
   "source": [
    "print(dict(model['model'].named_parameters())['fc.f7.bias'])\n",
    "print(dict(loaded_model.named_parameters())['fc.f7.bias'])\n",
    "print(src.dnn.test.test(model['model'], test_dataset, loss=torch.nn.CrossEntropyLoss()))\n",
    "print(src.dnn.test.test(loaded_model, test_dataset, loss=torch.nn.CrossEntropyLoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model['model'].state_dict(), 'models/lenet5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "GPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n\n  | Name    | Type   | Params\n-----------------------------------\n0 | layer_1 | Linear | 100 K \n1 | layer_2 | Linear | 33 K  \n2 | layer_3 | Linear | 2 K   \nEpoch 1:  92%|█████████▏| 860/939 [00:11<00:01, 73.37it/s, loss=0.130, v_num=14]\nEpoch 1:  93%|█████████▎| 869/939 [00:11<00:00, 73.51it/s, loss=0.130, v_num=14]\nEpoch 1:  94%|█████████▎| 880/939 [00:11<00:00, 73.78it/s, loss=0.130, v_num=14]\nValidating:  27%|██▋       | 21/79 [00:00<00:00, 96.40it/s]\u001b[A\nEpoch 1:  95%|█████████▍| 891/939 [00:12<00:00, 74.00it/s, loss=0.130, v_num=14]\nEpoch 1:  96%|█████████▌| 902/939 [00:12<00:00, 74.13it/s, loss=0.130, v_num=14]\nEpoch 1:  97%|█████████▋| 913/939 [00:12<00:00, 74.39it/s, loss=0.130, v_num=14]\nEpoch 1:  98%|█████████▊| 924/939 [00:12<00:00, 74.63it/s, loss=0.130, v_num=14]\nEpoch 1: 100%|██████████| 939/939 [00:12<00:00, 74.62it/s, loss=0.130, v_num=14]\nEpoch 1: 100%|██████████| 939/939 [00:12<00:00, 74.61it/s, loss=0.130, v_num=14]\nTesting: 0it [00:00, ?it/s]tensor(0.0636, device='cuda:0')\ntensor(0.0369, device='cuda:0')\ntensor(0.0620, device='cuda:0')\ntensor(0.1626, device='cuda:0')\ntensor(0.0678, device='cuda:0')\ntensor(0.1659, device='cuda:0')\ntensor(0.0874, device='cuda:0')\ntensor(0.1190, device='cuda:0')\nTesting:   5%|▌         | 8/157 [00:00<00:02, 73.88it/s]tensor(0.0809, device='cuda:0')\ntensor(0.2459, device='cuda:0')\ntensor(0.1248, device='cuda:0')\ntensor(0.1696, device='cuda:0')\ntensor(0.0275, device='cuda:0')\ntensor(0.0664, device='cuda:0')\ntensor(0.2482, device='cuda:0')\ntensor(0.1628, device='cuda:0')\ntensor(0.1335, device='cuda:0')\nTesting:  11%|█         | 17/157 [00:00<00:01, 76.83it/s]tensor(0.1715, device='cuda:0')\ntensor(0.2566, device='cuda:0')\ntensor(0.4266, device='cuda:0')\ntensor(0.2553, device='cuda:0')\ntensor(0.1155, device='cuda:0')\ntensor(0.0885, device='cuda:0')\ntensor(0.2639, device='cuda:0')\ntensor(0.1939, device='cuda:0')\ntensor(0.1874, device='cuda:0')\nTesting:  17%|█▋        | 26/157 [00:00<00:01, 79.92it/s]tensor(0.2438, device='cuda:0')\ntensor(0.1997, device='cuda:0')\ntensor(0.0559, device='cuda:0')\ntensor(0.1156, device='cuda:0')\ntensor(0.2408, device='cuda:0')\ntensor(0.3244, device='cuda:0')\ntensor(0.2726, device='cuda:0')\ntensor(0.2024, device='cuda:0')\ntensor(0.3098, device='cuda:0')\ntensor(0.2457, device='cuda:0')\nTesting:  23%|██▎       | 36/157 [00:00<00:01, 83.86it/s]tensor(0.0678, device='cuda:0')\ntensor(0.2097, device='cuda:0')\ntensor(0.1196, device='cuda:0')\ntensor(0.0417, device='cuda:0')\ntensor(0.1138, device='cuda:0')\ntensor(0.2342, device='cuda:0')\ntensor(0.1055, device='cuda:0')\ntensor(0.1104, device='cuda:0')\ntensor(0.0570, device='cuda:0')\ntensor(0.1627, device='cuda:0')\nTesting:  29%|██▉       | 46/157 [00:00<00:01, 86.42it/s]tensor(0.1753, device='cuda:0')\ntensor(0.0500, device='cuda:0')\ntensor(0.3029, device='cuda:0')\ntensor(0.1130, device='cuda:0')\ntensor(0.1413, device='cuda:0')\ntensor(0.0718, device='cuda:0')\ntensor(0.0965, device='cuda:0')\ntensor(0.0667, device='cuda:0')\ntensor(0.1321, device='cuda:0')\nTesting:  35%|███▌      | 55/157 [00:00<00:01, 87.40it/s]tensor(0.2361, device='cuda:0')\ntensor(0.1124, device='cuda:0')\ntensor(0.0803, device='cuda:0')\ntensor(0.1693, device='cuda:0')\ntensor(0.2939, device='cuda:0')\ntensor(0.1827, device='cuda:0')\ntensor(0.3181, device='cuda:0')\ntensor(0.1089, device='cuda:0')\ntensor(0.1520, device='cuda:0')\nTesting:  41%|████      | 64/157 [00:00<00:01, 87.23it/s]tensor(0.0283, device='cuda:0')\ntensor(0.1349, device='cuda:0')\ntensor(0.1745, device='cuda:0')\ntensor(0.2489, device='cuda:0')\ntensor(0.1667, device='cuda:0')\ntensor(0.1866, device='cuda:0')\ntensor(0.1448, device='cuda:0')\ntensor(0.1472, device='cuda:0')\ntensor(0.0694, device='cuda:0')\nTesting:  46%|████▋     | 73/157 [00:00<00:00, 87.85it/s]tensor(0.0813, device='cuda:0')\ntensor(0.0803, device='cuda:0')\ntensor(0.1702, device='cuda:0')\ntensor(0.1508, device='cuda:0')\ntensor(0.2083, device='cuda:0')\ntensor(0.0693, device='cuda:0')\ntensor(0.0633, device='cuda:0')\ntensor(0.0841, device='cuda:0')\ntensor(0.0594, device='cuda:0')\ntensor(0.0242, device='cuda:0')\nTesting:  53%|█████▎    | 83/157 [00:00<00:00, 89.52it/s]tensor(0.1053, device='cuda:0')\ntensor(0.0406, device='cuda:0')\ntensor(0.0556, device='cuda:0')\ntensor(0.0144, device='cuda:0')\ntensor(0.0558, device='cuda:0')\ntensor(0.1754, device='cuda:0')\ntensor(0.1301, device='cuda:0')\ntensor(0.0095, device='cuda:0')\ntensor(0.1383, device='cuda:0')\ntensor(0.1693, device='cuda:0')\nTesting:  59%|█████▉    | 93/157 [00:01<00:00, 89.93it/s]tensor(0.2496, device='cuda:0')\ntensor(0.1936, device='cuda:0')\ntensor(0.0831, device='cuda:0')\ntensor(0.1169, device='cuda:0')\ntensor(0.0031, device='cuda:0')\ntensor(0.0038, device='cuda:0')\ntensor(0.1128, device='cuda:0')\ntensor(0.1219, device='cuda:0')\ntensor(0.0632, device='cuda:0')\ntensor(0.2354, device='cuda:0')\nTesting:  66%|██████▌   | 103/157 [00:01<00:00, 90.25it/s]tensor(0.2619, device='cuda:0')\ntensor(0.0357, device='cuda:0')\ntensor(0.1335, device='cuda:0')\ntensor(0.0317, device='cuda:0')\ntensor(0.0429, device='cuda:0')\ntensor(0.0120, device='cuda:0')\ntensor(0.0116, device='cuda:0')\ntensor(0.0538, device='cuda:0')\ntensor(0.0325, device='cuda:0')\ntensor(0.0786, device='cuda:0')\nTesting:  72%|███████▏  | 113/157 [00:01<00:00, 91.45it/s]tensor(0.0260, device='cuda:0')\ntensor(0.0385, device='cuda:0')\ntensor(0.0249, device='cuda:0')\ntensor(0.1598, device='cuda:0')\ntensor(0.0488, device='cuda:0')\ntensor(0.0351, device='cuda:0')\ntensor(0.0195, device='cuda:0')\ntensor(0.0177, device='cuda:0')\ntensor(0.0335, device='cuda:0')\ntensor(0.1137, device='cuda:0')\nTesting:  78%|███████▊  | 123/157 [00:01<00:00, 90.71it/s]tensor(0.1652, device='cuda:0')\ntensor(0.1256, device='cuda:0')\ntensor(0.0786, device='cuda:0')\ntensor(0.1408, device='cuda:0')\ntensor(0.0233, device='cuda:0')\ntensor(0.0643, device='cuda:0')\ntensor(0.0813, device='cuda:0')\ntensor(0.1067, device='cuda:0')\ntensor(0.1000, device='cuda:0')\ntensor(0.0238, device='cuda:0')\nTesting:  85%|████████▍ | 133/157 [00:01<00:00, 83.80it/s]tensor(0.0873, device='cuda:0')\ntensor(0.0272, device='cuda:0')\ntensor(0.0037, device='cuda:0')\ntensor(0.0043, device='cuda:0')\ntensor(0.0023, device='cuda:0')\ntensor(0.0055, device='cuda:0')\ntensor(0.0223, device='cuda:0')\ntensor(0.1711, device='cuda:0')\ntensor(0.1109, device='cuda:0')\nTesting:  90%|█████████ | 142/157 [00:01<00:00, 83.05it/s]tensor(0.0146, device='cuda:0')\ntensor(0.0528, device='cuda:0')\ntensor(0.0098, device='cuda:0')\ntensor(0.0517, device='cuda:0')\ntensor(0.0042, device='cuda:0')\ntensor(0.0124, device='cuda:0')\ntensor(0.0307, device='cuda:0')\ntensor(0.1126, device='cuda:0')\ntensor(0.2116, device='cuda:0')\nTesting:  96%|█████████▌| 151/157 [00:01<00:00, 83.02it/s]tensor(0.1728, device='cuda:0')\ntensor(0.4356, device='cuda:0')\ntensor(0.2410, device='cuda:0')\ntensor(0.2071, device='cuda:0')\ntensor(0.2670, device='cuda:0')\ntensor(0.0287, device='cuda:0')\nTesting: 100%|██████████| 157/157 [00:01<00:00, 87.28it/s]\n1\nTesting: 0it [00:00, ?it/s]tensor(0.0636, device='cuda:0')\ntensor(0.0369, device='cuda:0')\ntensor(0.0620, device='cuda:0')\ntensor(0.1626, device='cuda:0')\ntensor(0.0678, device='cuda:0')\ntensor(0.1659, device='cuda:0')\ntensor(0.0874, device='cuda:0')\ntensor(0.1190, device='cuda:0')\ntensor(0.0809, device='cuda:0')\nTesting:   6%|▌         | 9/157 [00:00<00:01, 87.56it/s]tensor(0.2459, device='cuda:0')\ntensor(0.1248, device='cuda:0')\ntensor(0.1696, device='cuda:0')\ntensor(0.0275, device='cuda:0')\ntensor(0.0664, device='cuda:0')\ntensor(0.2482, device='cuda:0')\ntensor(0.1628, device='cuda:0')\nTesting:  10%|█         | 16/157 [00:00<00:01, 80.01it/s]tensor(0.1335, device='cuda:0')\ntensor(0.1715, device='cuda:0')\ntensor(0.2566, device='cuda:0')\ntensor(0.4266, device='cuda:0')\ntensor(0.2553, device='cuda:0')\ntensor(0.1155, device='cuda:0')\ntensor(0.0885, device='cuda:0')\nTesting:  15%|█▍        | 23/157 [00:00<00:01, 76.09it/s]tensor(0.2639, device='cuda:0')\ntensor(0.1939, device='cuda:0')\ntensor(0.1874, device='cuda:0')\ntensor(0.2438, device='cuda:0')\ntensor(0.1997, device='cuda:0')\ntensor(0.0559, device='cuda:0')\ntensor(0.1156, device='cuda:0')\nTesting:  19%|█▉        | 30/157 [00:00<00:01, 71.55it/s]tensor(0.2408, device='cuda:0')\ntensor(0.3244, device='cuda:0')\ntensor(0.2726, device='cuda:0')\ntensor(0.2024, device='cuda:0')\ntensor(0.3098, device='cuda:0')\ntensor(0.2457, device='cuda:0')\ntensor(0.0678, device='cuda:0')\ntensor(0.2097, device='cuda:0')\nTesting:  24%|██▍       | 38/157 [00:00<00:01, 73.73it/s]tensor(0.1196, device='cuda:0')\ntensor(0.0417, device='cuda:0')\ntensor(0.1138, device='cuda:0')\ntensor(0.2342, device='cuda:0')\ntensor(0.1055, device='cuda:0')\ntensor(0.1104, device='cuda:0')\ntensor(0.0570, device='cuda:0')\ntensor(0.1627, device='cuda:0')\ntensor(0.1753, device='cuda:0')\nTesting:  30%|██▉       | 47/157 [00:00<00:01, 76.73it/s]tensor(0.0500, device='cuda:0')\ntensor(0.3029, device='cuda:0')\ntensor(0.1130, device='cuda:0')\ntensor(0.1413, device='cuda:0')\ntensor(0.0718, device='cuda:0')\ntensor(0.0965, device='cuda:0')\ntensor(0.0667, device='cuda:0')\nTesting:  34%|███▍      | 54/157 [00:00<00:01, 73.56it/s]tensor(0.1321, device='cuda:0')\ntensor(0.2361, device='cuda:0')\ntensor(0.1124, device='cuda:0')\ntensor(0.0803, device='cuda:0')\ntensor(0.1693, device='cuda:0')\ntensor(0.2939, device='cuda:0')\ntensor(0.1827, device='cuda:0')\nTesting:  39%|███▉      | 61/157 [00:00<00:01, 68.25it/s]tensor(0.3181, device='cuda:0')\ntensor(0.1089, device='cuda:0')\ntensor(0.1520, device='cuda:0')\ntensor(0.0283, device='cuda:0')\ntensor(0.1349, device='cuda:0')\ntensor(0.1745, device='cuda:0')\ntensor(0.2489, device='cuda:0')\nTesting:  43%|████▎     | 68/157 [00:00<00:01, 67.11it/s]tensor(0.1667, device='cuda:0')\ntensor(0.1866, device='cuda:0')\ntensor(0.1448, device='cuda:0')\ntensor(0.1472, device='cuda:0')\ntensor(0.0694, device='cuda:0')\ntensor(0.0813, device='cuda:0')\ntensor(0.0803, device='cuda:0')\nTesting:  48%|████▊     | 75/157 [00:01<00:01, 64.74it/s]tensor(0.1702, device='cuda:0')\ntensor(0.1508, device='cuda:0')\ntensor(0.2083, device='cuda:0')\ntensor(0.0693, device='cuda:0')\ntensor(0.0633, device='cuda:0')\ntensor(0.0841, device='cuda:0')\ntensor(0.0594, device='cuda:0')\nTesting:  52%|█████▏    | 82/157 [00:01<00:01, 62.60it/s]tensor(0.0242, device='cuda:0')\ntensor(0.1053, device='cuda:0')\ntensor(0.0406, device='cuda:0')\ntensor(0.0556, device='cuda:0')\ntensor(0.0144, device='cuda:0')\ntensor(0.0558, device='cuda:0')\ntensor(0.1754, device='cuda:0')\nTesting:  57%|█████▋    | 89/157 [00:01<00:01, 63.72it/s]tensor(0.1301, device='cuda:0')\ntensor(0.0095, device='cuda:0')\ntensor(0.1383, device='cuda:0')\ntensor(0.1693, device='cuda:0')\ntensor(0.2496, device='cuda:0')\ntensor(0.1936, device='cuda:0')\ntensor(0.0831, device='cuda:0')\ntensor(0.1169, device='cuda:0')\nTesting:  62%|██████▏   | 97/157 [00:01<00:00, 65.29it/s]tensor(0.0031, device='cuda:0')\ntensor(0.0038, device='cuda:0')\ntensor(0.1128, device='cuda:0')\ntensor(0.1219, device='cuda:0')\ntensor(0.0632, device='cuda:0')\ntensor(0.2354, device='cuda:0')\ntensor(0.2619, device='cuda:0')\nTesting:  66%|██████▌   | 104/157 [00:01<00:00, 62.23it/s]tensor(0.0357, device='cuda:0')\ntensor(0.1335, device='cuda:0')\ntensor(0.0317, device='cuda:0')\ntensor(0.0429, device='cuda:0')\ntensor(0.0120, device='cuda:0')\ntensor(0.0116, device='cuda:0')\ntensor(0.0538, device='cuda:0')\nTesting:  71%|███████   | 111/157 [00:01<00:00, 61.96it/s]tensor(0.0325, device='cuda:0')\ntensor(0.0786, device='cuda:0')\ntensor(0.0260, device='cuda:0')\ntensor(0.0385, device='cuda:0')\ntensor(0.0249, device='cuda:0')\ntensor(0.1598, device='cuda:0')\ntensor(0.0488, device='cuda:0')\nTesting:  75%|███████▌  | 118/157 [00:01<00:00, 61.62it/s]tensor(0.0351, device='cuda:0')\ntensor(0.0195, device='cuda:0')\ntensor(0.0177, device='cuda:0')\ntensor(0.0335, device='cuda:0')\ntensor(0.1137, device='cuda:0')\ntensor(0.1652, device='cuda:0')\ntensor(0.1256, device='cuda:0')\nTesting:  80%|███████▉  | 125/157 [00:01<00:00, 60.40it/s]tensor(0.0786, device='cuda:0')\ntensor(0.1408, device='cuda:0')\ntensor(0.0233, device='cuda:0')\ntensor(0.0643, device='cuda:0')\ntensor(0.0813, device='cuda:0')\ntensor(0.1067, device='cuda:0')\ntensor(0.1000, device='cuda:0')\nTesting:  84%|████████▍ | 132/157 [00:02<00:00, 61.65it/s]tensor(0.0238, device='cuda:0')\ntensor(0.0873, device='cuda:0')\ntensor(0.0272, device='cuda:0')\ntensor(0.0037, device='cuda:0')\ntensor(0.0043, device='cuda:0')\ntensor(0.0023, device='cuda:0')\ntensor(0.0055, device='cuda:0')\nTesting:  89%|████████▊ | 139/157 [00:02<00:00, 61.73it/s]tensor(0.0223, device='cuda:0')\ntensor(0.1711, device='cuda:0')\ntensor(0.1109, device='cuda:0')\ntensor(0.0146, device='cuda:0')\ntensor(0.0528, device='cuda:0')\ntensor(0.0098, device='cuda:0')\ntensor(0.0517, device='cuda:0')\nTesting:  93%|█████████▎| 146/157 [00:02<00:00, 59.13it/s]tensor(0.0042, device='cuda:0')\ntensor(0.0124, device='cuda:0')\ntensor(0.0307, device='cuda:0')\ntensor(0.1126, device='cuda:0')\ntensor(0.2116, device='cuda:0')\ntensor(0.1728, device='cuda:0')\ntensor(0.4356, device='cuda:0')\nTesting:  97%|█████████▋| 153/157 [00:02<00:00, 61.81it/s]tensor(0.2410, device='cuda:0')\ntensor(0.2071, device='cuda:0')\ntensor(0.2670, device='cuda:0')\ntensor(0.0287, device='cuda:0')\nTesting: 100%|██████████| 157/157 [00:02<00:00, 65.45it/s]\n1\n"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LightningMNISTClassifier, self).__init__()\n",
    "\n",
    "        self.enable = False\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height) \n",
    "        self.layer_1 = torch.nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = torch.nn.Linear(128, 256)\n",
    "        self.layer_3 = torch.nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # layer 1 (b, 1*28*28) -> (b, 128)\n",
    "        x = self.layer_1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 2 (b, 128) -> (b, 256)\n",
    "        x = self.layer_2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 3 (b, 256) -> (b, 10)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        # probability distribution over labels\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        x, y = test_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        print(loss)\n",
    "        return {'test_loss': loss}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # called at the end of the validation epoch\n",
    "        # outputs is an array with what you returned in validation_step for each batch\n",
    "        # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # transforms for images\n",
    "        transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        \n",
    "        # prepare transforms standard to MNIST\n",
    "        mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "        mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "        \n",
    "        self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
    "        self.mnist_test = mnist_test\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=64)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=64)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=64)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def on_test_start(self):\n",
    "        if self.enable:\n",
    "            self.layer_1 = torch.nn.Sequential(self.layer_1, torch.nn.Softmax())\n",
    "\n",
    "    def enable_(self):\n",
    "        self.enable = True\n",
    "\n",
    "# train\n",
    "model = LightningMNISTClassifier()\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=1)\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "print(trainer.test(model))\n",
    "\n",
    "#model.layer_1 = torch.nn.Sequential(model.layer_1, torch.nn.Softmax())\n",
    "model.enable_()\n",
    "print(trainer.test(model))\n",
    "\n",
    "# trainer.test() does not work if we change the model\n",
    "#for i, test_batch in enumerate(model.test_dataloader()):\n",
    "#    x, y = test_batch\n",
    "#    logits = model.forward(x.to(model.device))\n",
    "#    loss = model.cross_entropy_loss(logits, y.to(model.device))\n",
    "#    print({'test_loss': loss})"
   ]
  }
 ]
}