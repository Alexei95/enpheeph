{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit982530fbef5f416d902730fdb3b376bf",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LightningMNISTClassifier, self).__init__()\n",
    "\n",
    "        self.enable = False\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height) \n",
    "        self.layer_1 = torch.nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = torch.nn.Linear(128, 256)\n",
    "        self.layer_3 = torch.nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # layer 1 (b, 1*28*28) -> (b, 128)\n",
    "        x = self.layer_1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 2 (b, 128) -> (b, 256)\n",
    "        x = self.layer_2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # layer 3 (b, 256) -> (b, 10)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        # probability distribution over labels\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        x, y = test_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        logs = {'test_loss': loss}\n",
    "        return {'test_loss': loss, 'log': logs}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # called at the end of the validation epoch\n",
    "        # outputs is an array with what you returned in validation_step for each batch\n",
    "        # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # called at the end of the validation epoch\n",
    "        # outputs is an array with what you returned in validation_step for each batch\n",
    "        # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'test_loss': avg_loss}\n",
    "        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # transforms for images\n",
    "        transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        \n",
    "        # prepare transforms standard to MNIST\n",
    "        mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "        mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "        \n",
    "        self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
    "        self.mnist_test = mnist_test\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=64)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=64)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=64)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "# train\n",
    "#model = LightningMNISTClassifier()\n",
    "#trainer = pl.Trainer(gpus=1, max_epochs=1)\n",
    "\n",
    "#trainer.fit(model)\n",
    "\n",
    "#print(trainer.test(model))\n",
    "\n",
    "#model.layer_1 = torch.nn.Sequential(model.layer_1, torch.nn.Softmax())\n",
    "#print(trainer.test(model))\n",
    "\n",
    "# trainer.test() does not work if we change the model\n",
    "#for i, test_batch in enumerate(model.test_dataloader()):\n",
    "#    x, y = test_batch\n",
    "#    logits = model.forward(x.to(model.device))\n",
    "#    loss = model.cross_entropy_loss(logits, y.to(model.device))\n",
    "#    print({'test_loss': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nTesting:  96%|█████████▌| 150/157 [00:01<00:00, 122.24it/s]--------------------------------------------------------------------------------\nTEST RESULTS\n{'avg_test_loss': tensor(2.3066), 'test_loss': tensor(2.3066)}\n--------------------------------------------------------------------------------\nTesting: 100%|██████████| 157/157 [00:01<00:00, 119.36it/s]\n  | Name    | Type   | Params\n-----------------------------------\n0 | layer_1 | Linear | 100 K \n1 | layer_2 | Linear | 33 K  \n2 | layer_3 | Linear | 2 K   \n\n{'avg_test_loss': 2.3066279888153076, 'test_loss': 2.3066279888153076}\nEpoch 1:  92%|█████████▏| 860/939 [00:10<00:00, 79.05it/s, loss=0.103, v_num=3]\nEpoch 1:  92%|█████████▏| 862/939 [00:10<00:00, 79.07it/s, loss=0.103, v_num=3]\nEpoch 1:  93%|█████████▎| 873/939 [00:11<00:00, 79.35it/s, loss=0.103, v_num=3]\nEpoch 1:  94%|█████████▍| 884/939 [00:11<00:00, 79.61it/s, loss=0.103, v_num=3]\nEpoch 1:  95%|█████████▌| 895/939 [00:11<00:00, 79.87it/s, loss=0.103, v_num=3]\nEpoch 1:  96%|█████████▋| 906/939 [00:11<00:00, 80.13it/s, loss=0.103, v_num=3]\nEpoch 1:  98%|█████████▊| 918/939 [00:11<00:00, 80.44it/s, loss=0.103, v_num=3]\nEpoch 1: 100%|██████████| 939/939 [00:11<00:00, 81.05it/s, loss=0.103, v_num=3]\nEpoch 1: 100%|██████████| 939/939 [00:11<00:00, 81.03it/s, loss=0.103, v_num=3]\nTesting:  96%|█████████▌| 151/157 [00:01<00:00, 121.78it/s]--------------------------------------------------------------------------------\nTEST RESULTS\n{'avg_test_loss': tensor(0.1330), 'test_loss': tensor(0.1330)}\n--------------------------------------------------------------------------------\nTesting: 100%|██████████| 157/157 [00:01<00:00, 121.17it/s]\n{'avg_test_loss': 0.1329713761806488, 'test_loss': 0.1329713761806488}\nTesting:  97%|█████████▋| 152/157 [00:01<00:00, 120.10it/s]--------------------------------------------------------------------------------\nTEST RESULTS\n{'avg_test_loss': tensor(37.1409), 'test_loss': tensor(37.1409)}\n--------------------------------------------------------------------------------\nTesting: 100%|██████████| 157/157 [00:01<00:00, 121.41it/s]\n{'avg_test_loss': 37.14088439941406, 'test_loss': 37.14088439941406}\n"
    }
   ],
   "source": [
    "# testing callbacks for new implementation of fault injection\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class A(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        x[0] = 1000\n",
    "        return x\n",
    "\n",
    "class Callback(pl.Callback):\n",
    "    def on_test_start(self, trainer, pl_module):\n",
    "        pl_module.layer_1 = torch.nn.Sequential(pl_module.layer_1, A())\n",
    "        #print('test start', pl_module.layer_1)\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        #print('test end', pl_module.layer_1)\n",
    "        pl_module.layer_1 = pl_module.layer_1[0]\n",
    "\n",
    "\n",
    "model = LightningMNISTClassifier()\n",
    "trainer1 = pl.Trainer(max_epochs=1, callbacks=[Callback()])\n",
    "trainer2 = pl.Trainer(max_epochs=1)\n",
    "\n",
    "print(trainer2.test(model))\n",
    "\n",
    "trainer2.fit(model)\n",
    "\n",
    "model_copy = copy.deepcopy(model)\n",
    "model_copy.load_state_dict(model.state_dict())\n",
    "\n",
    "print(trainer2.test(model_copy))\n",
    "print(trainer1.test(model_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OrderedDict([('layer_1.weight',\n              tensor([[-2.9835e-02, -1.0588e-02,  2.3553e-02,  ..., -9.3428e-03,\n                       -2.3920e-02, -7.5001e-03],\n                      [-2.9323e-03,  3.1080e-02, -2.2315e-02,  ...,  2.2397e-02,\n                       -8.4179e-04, -1.8313e-02],\n                      [-6.5292e-03,  9.8052e-03,  2.7756e-02,  ..., -2.9047e-02,\n                       -9.5493e-03, -5.1596e-03],\n                      ...,\n                      [ 3.5459e-02,  3.4426e-02,  6.8589e-03,  ..., -8.5028e-03,\n                        3.2896e-02,  6.1409e-03],\n                      [-7.2285e-03,  9.5989e-03,  4.0405e-03,  ...,  4.4267e-02,\n                       -1.0017e-02,  1.1489e-02],\n                      [ 5.1586e-03, -2.3910e-05, -2.8683e-02,  ..., -3.1008e-02,\n                        2.4692e-02, -1.1857e-02]])),\n             ('layer_1.bias',\n              tensor([ 0.0248,  0.0043,  0.0127,  0.0349, -0.0297,  0.0080,  0.0109,  0.0394,\n                       0.0184,  0.0069,  0.0056, -0.0168,  0.0142, -0.0295,  0.0057,  0.0141,\n                       0.0391, -0.0058,  0.0272,  0.0154,  0.0333,  0.0283, -0.0107,  0.0189,\n                      -0.0315,  0.0115, -0.0226, -0.0140,  0.0021,  0.0113, -0.0048,  0.0196,\n                       0.0198, -0.0215,  0.0114,  0.0321, -0.0320,  0.0024, -0.0112, -0.0223,\n                      -0.0301,  0.0267, -0.0263,  0.0007, -0.0156, -0.0069, -0.0326,  0.0091,\n                       0.0051, -0.0289, -0.0463,  0.0280,  0.0100, -0.0364, -0.0031,  0.0241,\n                       0.0256, -0.0443, -0.0045, -0.0053,  0.0036, -0.0150, -0.0213,  0.0100,\n                       0.0011,  0.0135, -0.0287, -0.0166, -0.0283, -0.0086,  0.0196,  0.0274,\n                       0.0066,  0.0226, -0.0256, -0.0305,  0.0259,  0.0155,  0.0214,  0.0090,\n                      -0.0386,  0.0196,  0.0207,  0.0345, -0.0406,  0.0319,  0.0208,  0.0309,\n                       0.0187,  0.0119, -0.0097,  0.0026, -0.0123,  0.0080,  0.0331,  0.0096,\n                      -0.0080, -0.0245,  0.0316, -0.0195, -0.0144, -0.0209,  0.0158,  0.0106,\n                       0.0336,  0.0018,  0.0058,  0.0229,  0.0185,  0.0099,  0.0078, -0.0093,\n                      -0.0156,  0.0266,  0.0121,  0.0072, -0.0192,  0.0216, -0.0056, -0.0288,\n                       0.0051,  0.0299, -0.0295,  0.0073,  0.0202,  0.0218, -0.0187,  0.0230])),\n             ('layer_2.weight',\n              tensor([[ 0.1303,  0.0693,  0.0623,  ..., -0.1007, -0.0562, -0.0115],\n                      [ 0.1156, -0.0403,  0.0135,  ...,  0.0047,  0.0537,  0.0351],\n                      [-0.0132, -0.0836,  0.0464,  ..., -0.0566, -0.0228, -0.0276],\n                      ...,\n                      [-0.0090, -0.0507,  0.0965,  ..., -0.0542, -0.0322, -0.0349],\n                      [-0.0546,  0.0457,  0.0791,  ...,  0.0881, -0.0127, -0.0596],\n                      [-0.0834,  0.0854, -0.0232,  ...,  0.0532, -0.0435,  0.0455]])),\n             ('layer_2.bias',\n              tensor([ 0.0391,  0.0186, -0.0002,  0.0205,  0.0690,  0.0305, -0.0598, -0.0191,\n                       0.0325,  0.0119,  0.0835,  0.0764,  0.0788,  0.0593,  0.0830,  0.0763,\n                       0.0530, -0.0565,  0.0234, -0.0471,  0.0163,  0.0492, -0.0282, -0.0550,\n                       0.0272, -0.0018,  0.0372,  0.0054, -0.0606, -0.0768, -0.0834,  0.0962,\n                       0.0252,  0.0961, -0.0682, -0.0974, -0.0075, -0.0620, -0.0295,  0.0735,\n                       0.0072,  0.0152, -0.0797, -0.0125,  0.0122, -0.0525,  0.0996,  0.0139,\n                      -0.0160, -0.0089,  0.0628,  0.0274, -0.0464, -0.0806,  0.0396, -0.0759,\n                      -0.0426,  0.0850,  0.0372, -0.0951,  0.0870, -0.0113, -0.0117, -0.0346,\n                      -0.0378, -0.0719,  0.0212, -0.0501,  0.0927,  0.0540,  0.0038,  0.0013,\n                       0.0503, -0.0247,  0.0561,  0.0249, -0.0351,  0.0863,  0.0586, -0.0503,\n                      -0.0465, -0.0335,  0.0554, -0.0850,  0.0282, -0.0206, -0.0410, -0.0395,\n                      -0.0612,  0.0388,  0.0004,  0.0080, -0.0575, -0.0523,  0.0593,  0.0579,\n                      -0.0679,  0.0935,  0.0071, -0.0794, -0.0181, -0.0089, -0.0917, -0.0595,\n                       0.0650, -0.0225, -0.0484,  0.0613,  0.0326,  0.0517,  0.0117,  0.0126,\n                      -0.0651,  0.0635,  0.0958, -0.0154,  0.0597,  0.0659, -0.1007, -0.0373,\n                       0.0892,  0.0677, -0.0672,  0.0632,  0.0097, -0.0388, -0.0409,  0.0127,\n                       0.0662, -0.0296, -0.0507, -0.0444, -0.0033, -0.0245,  0.0688,  0.0806,\n                      -0.0745, -0.0431, -0.0075, -0.0344,  0.0249,  0.0413, -0.0567,  0.1120,\n                       0.0622, -0.0462, -0.0300, -0.0234, -0.0960,  0.0170, -0.0111, -0.0534,\n                       0.0433,  0.0741,  0.0665,  0.0690, -0.0451, -0.0461,  0.0169, -0.0450,\n                      -0.0066,  0.0473,  0.0309,  0.0735,  0.0587,  0.0213,  0.0271,  0.0172,\n                      -0.0851,  0.0897,  0.0645,  0.0873, -0.0583, -0.0354,  0.0506,  0.0239,\n                      -0.0353,  0.0248, -0.0455, -0.0241,  0.0786,  0.0067,  0.0075,  0.0911,\n                       0.0277, -0.0648,  0.0726,  0.0361, -0.0243,  0.0325, -0.0221,  0.1118,\n                      -0.0192,  0.0659,  0.0674, -0.0486, -0.0444, -0.0232,  0.0687, -0.0568,\n                      -0.0517,  0.0420, -0.0723,  0.0532, -0.0678,  0.0440, -0.0086,  0.0797,\n                       0.0586,  0.0984,  0.0661, -0.0629, -0.0869,  0.0799,  0.0260,  0.0175,\n                       0.0228,  0.0535, -0.0731,  0.0365,  0.0115,  0.0086, -0.0224, -0.0229,\n                      -0.0774,  0.0765, -0.0770, -0.0510,  0.0119, -0.0078,  0.0147, -0.0035,\n                       0.0293,  0.0623, -0.0118,  0.0117, -0.0653,  0.0717,  0.0173, -0.0402,\n                      -0.0672, -0.0905, -0.0510, -0.0483, -0.0115, -0.1012, -0.0092,  0.0128,\n                       0.0720,  0.0855, -0.0748,  0.0674, -0.0347,  0.0334,  0.0683,  0.0322])),\n             ('layer_3.weight',\n              tensor([[-0.0900, -0.1038,  0.0138,  ..., -0.0423,  0.0591, -0.0281],\n                      [ 0.0730, -0.0514,  0.0291,  ...,  0.0006, -0.0896,  0.0481],\n                      [ 0.0762,  0.0173,  0.0399,  ..., -0.0034,  0.0052,  0.0709],\n                      ...,\n                      [ 0.0505, -0.0120,  0.0426,  ...,  0.0827,  0.0304, -0.0028],\n                      [-0.0688, -0.0420, -0.0229,  ..., -0.0628,  0.0217, -0.0504],\n                      [-0.0894, -0.0926, -0.0080,  ...,  0.0662,  0.0380, -0.1560]])),\n             ('layer_3.bias',\n              tensor([ 0.0352, -0.0789, -0.0206, -0.0110,  0.0240,  0.0382,  0.0118, -0.0205,\n                      -0.0188, -0.0436]))])"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model_copy.state_dict()"
   ]
  }
 ]
}